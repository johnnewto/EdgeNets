{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History\n",
    "17/07/2019 - workingon simulated dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTaWM3mtNG4O",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import sys\n",
    "# fai_dir = '/home/john/github/fastai'\n",
    "# if fai_dir not in sys.path:\n",
    "#     sys.path = ['/home/john/github/fastai'] + sys.path\n",
    "    \n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "fastai==1.0.55\r\ntorch==1.1.0\r\ntorchsummary==1.5.1\r\ntorchvision==0.3.0\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "! pip freeze | grep 'fastai\\|torch*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Wed Sep  4 06:15:34 2019       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Quadro M1200        Off  | 00000000:01:00.0 Off |                  N/A |\r\n| N/A   45C    P8    N/A /  N/A |      2MiB /  4046MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58DQJmGMx_1m",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "defaults.device = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "path_lbl = Path('/home/john/github/techion-expts/unet/data/sim-unet/labels/')\n",
    "path_img = Path('/home/john/github/techion-expts/unet/data/sim-unet/images/')\n",
    "\n",
    "get_label_fn = lambda x: path_lbl/f'{x.stem}.png'\n",
    "\n",
    "def show_img(im, figsize=None, ax=None, alpha=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1554262308914,
     "user": {
      "displayName": "John Newton",
      "photoUrl": "https://lh3.googleusercontent.com/-CaBsDb97lHU/AAAAAAAAAAI/AAAAAAAAB34/lWIwjHZsHPY/s64/photo.jpg",
      "userId": "07245927208614369629"
     },
     "user_tz": -780
    },
    "id": "88psKyfAtj-t",
    "outputId": "6864ba36-8f36-424d-802f-8cb174024c96",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = open_mask(f'{path_lbl}/img3.png')\n",
    "# im.data.mul_(50)?\n",
    "im.show(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1168,
     "status": "ok",
     "timestamp": 1554260236125,
     "user": {
      "displayName": "John Newton",
      "photoUrl": "https://lh3.googleusercontent.com/-CaBsDb97lHU/AAAAAAAAAAI/AAAAAAAAB34/lWIwjHZsHPY/s64/photo.jpg",
      "userId": "07245927208614369629"
     },
     "user_tz": -780
    },
    "id": "Q7OEh2zC0ifD",
    "outputId": "ce049fda-1a04-471a-d817-4983ab9098fc",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['background', 'triangle', 'circle1', 'circle2', 'square_f', 'plus'], dtype='<U10')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "codes = np.array(['background', 'triangle', 'circle1', 'circle2', 'square_f', 'plus'])\n",
    "codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "122giIBoM_5j"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1309,
     "status": "ok",
     "timestamp": 1556525969657,
     "user": {
      "displayName": "John Newton",
      "photoUrl": "https://lh3.googleusercontent.com/-CaBsDb97lHU/AAAAAAAAAAI/AAAAAAAAB34/lWIwjHZsHPY/s64/photo.jpg",
      "userId": "07245927208614369629"
     },
     "user_tz": -720
    },
    "id": "23Be8XJ30wZO",
    "outputId": "43d7b364-ead6-4d66-f9a4-c7ab948aa63f",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "bs=16\n",
    "size=128\n",
    "codes = np.array(['background', 'triangle', 'circle1', 'circle2', 'square_f', 'plus'])\n",
    "\n",
    "get_label_fn = lambda x: f'{path_lbl}/{x.stem}.png'\n",
    "src = (SegmentationItemList.from_folder(path_img)\n",
    "       .split_by_rand_pct(valid_pct=0.2, seed=42)\n",
    "       .label_from_func(get_label_fn, classes=codes))\n",
    "\n",
    "data = (src.transform(get_transforms(),  tfm_y=True)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14741,
     "status": "ok",
     "timestamp": 1554253706116,
     "user": {
      "displayName": "John Newton",
      "photoUrl": "https://lh3.googleusercontent.com/-CaBsDb97lHU/AAAAAAAAAAI/AAAAAAAAB34/lWIwjHZsHPY/s64/photo.jpg",
      "userId": "07245927208614369629"
     },
     "user_tz": -780
    },
    "id": "JYCNiK-W9Nsb",
    "outputId": "083fcc99-4dea-4b4a-c513-da4e0aa05af9",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array(['background', 'triangle', 'circle1', 'circle2', 'square_f', 'plus'], dtype='<U10'),\n 6)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "data.classes, data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 1, 150, 150])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "inputs, labels = next(iter(data.valid_dl))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13633,
     "status": "error",
     "timestamp": 1556526002374,
     "user": {
      "displayName": "John Newton",
      "photoUrl": "https://lh3.googleusercontent.com/-CaBsDb97lHU/AAAAAAAAAAI/AAAAAAAAB34/lWIwjHZsHPY/s64/photo.jpg",
      "userId": "07245927208614369629"
     },
     "user_tz": -720
    },
    "id": "Z4DKWmIsAHCN",
    "outputId": "e3a33e57-6da9-4342-dc1c-1259e7746db3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x432 with 16 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch(4, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pakysZSpLF9O"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvKCN-huA1bh",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "\n",
    "def acc_metric1(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "def acc_metric2(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)[target>0]==target[target>0]).float().mean()\n",
    "  \n",
    "\n",
    "metrics=[acc_metric1, acc_metric2]\n",
    "wd=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Simple Upsample\n",
    "\n",
    "class StdUpsample(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(nin, nout, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        \n",
    "    def forward(self, x): return self.bn(F.relu(self.conv(x)))\n",
    "    \n",
    "flatten_channel = Lambda(lambda x: x[:,0])\n",
    "unsqeeze_channel = Lambda(lambda x: x.unsqueeze_(1))\n",
    "\n",
    "class Upsample34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "#         self.rn = rn\n",
    "        self.features = nn.Sequential(\n",
    "            rn,\n",
    "            nn.ReLU(),\n",
    "            StdUpsample(512,256),\n",
    "            StdUpsample(256,256),\n",
    "            StdUpsample(256,256),\n",
    "            StdUpsample(256,256),\n",
    "            nn.ConvTranspose2d(256, 1, 2, stride=2),\n",
    "            unsqeeze_channel)   \n",
    "            \n",
    "    def forward(self,x): return self.features(x)[:,0]\n",
    "\n",
    "class UpsampleModel():\n",
    "    def __init__(self,model,name='upsample'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model.features)[1:]]\n",
    "  \n",
    "    \n",
    "m_base = create_body(models.resnet18)\n",
    "\n",
    "m = Upsample34(m_base)\n",
    "mod = UpsampleModel(m)\n",
    "\n",
    "## uses torch.nn.CrossEntropyLoss(...)    as a super class  \n",
    "class myLoss2(nn.BCEWithLogitsLoss):    \n",
    "    def __init__(self, weight=None):\n",
    "        super(myLoss2, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        target = target.float()\n",
    "        ret = super(myLoss2, self).forward(input, target)\n",
    "        return ret\n",
    "loss_func = myLoss2() \n",
    "\n",
    "def acc_camvid(input, target):\n",
    "#     target = target.float()\n",
    "        input = (input >0.5).long()\n",
    "        return (input==target).float().mean()\n",
    "lr=1e-4\n",
    "learn = Learner(data, mod.model, loss_func = loss_func, metrics = acc_camvid)\n",
    "# learn.fit_one_cycle(2, slice(lr), pct_start=0.9)\n",
    "# learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_modules(m, cond):\n",
    "    if cond(m): return [m]\n",
    "    return sum([find_modules(o,cond) for o in m.children()], [])\n",
    "\n",
    "def is_lin_layer(l):\n",
    "    lin_layers = (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.Linear, nn.ReLU)\n",
    "    return isinstance(l, lin_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make unet manual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7c7bc38019a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNetUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;31m# summary(m, (3, 224, 224))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    162\u001b[0m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (30) : unknown error at /pytorch/aten/src/THC/THCGeneral.cpp:51"
     ],
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (30) : unknown error at /pytorch/aten/src/THC/THCGeneral.cpp:51",
     "output_type": "error"
    }
   ],
   "source": [
    "# class ResNetUNet(nn.Module):\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "base_model = models.resnet18(pretrained=True)\n",
    "# keep all the layers upto the AdaptiveAvgPool2d layer\n",
    "cut = next(i for i,o in enumerate(base_model.children()) if isinstance(o,nn.AdaptiveAvgPool2d))\n",
    "base_model = nn.Sequential(*list(base_model.children())[:cut])\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())                \n",
    "        \n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)        \n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)       \n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)        \n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)        \n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)  \n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        layer0 = self.layer0(input)            \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)        \n",
    "        \n",
    "        return out\n",
    "    \n",
    "m = ResNetUNet(6).cuda()\n",
    "# summary(m, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1)),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(640, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def find_modules(m, cond):\n",
    "    if cond(m): return [m]\n",
    "    return sum([find_modules(o,cond) for o in m.children()], [])\n",
    "\n",
    "def is_lin_layer(l):\n",
    "    lin_layers = (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.Linear, nn.ReLU)\n",
    "    return isinstance(l, lin_layers)\n",
    "def is_conv_layer(l):\n",
    "    layers = (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.MaxPool2d, nn.AvgPool2d)\n",
    "    return isinstance(l, layers)\n",
    "\n",
    "list(m.children())\n",
    "find_modules(m, is_conv_layer)\n",
    "\n",
    "# base_model = models.resnet18(pretrained=True)\n",
    "# find_modules(base_model, is_conv_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 11,176,512\n",
      "Trainable params: 11,176,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.78\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 105.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(base_model.cuda(), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make UNet  model programatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-11           [-1, 64, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "             ReLU-14           [-1, 64, 32, 32]               0\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "             ReLU-17           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-18           [-1, 64, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "             ReLU-21           [-1, 64, 32, 32]               0\n",
      "           Conv2d-22           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 32, 32]             128\n",
      "             ReLU-24           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-25           [-1, 64, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 16, 16]             256\n",
      "             ReLU-28          [-1, 128, 16, 16]               0\n",
      "           Conv2d-29          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 16, 16]             256\n",
      "           Conv2d-31          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
      "             ReLU-33          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-34          [-1, 128, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 16, 16]             256\n",
      "             ReLU-37          [-1, 128, 16, 16]               0\n",
      "           Conv2d-38          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 16, 16]             256\n",
      "             ReLU-40          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-41          [-1, 128, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 16, 16]             256\n",
      "             ReLU-44          [-1, 128, 16, 16]               0\n",
      "           Conv2d-45          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "             ReLU-47          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "             ReLU-54          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-55          [-1, 128, 16, 16]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "           Conv2d-59            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 8, 8]             512\n",
      "           Conv2d-61            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-62            [-1, 256, 8, 8]             512\n",
      "             ReLU-63            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-64            [-1, 256, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "             ReLU-67            [-1, 256, 8, 8]               0\n",
      "           Conv2d-68            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 8, 8]             512\n",
      "             ReLU-70            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-71            [-1, 256, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "             ReLU-74            [-1, 256, 8, 8]               0\n",
      "           Conv2d-75            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 8, 8]             512\n",
      "             ReLU-77            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-78            [-1, 256, 8, 8]               0\n",
      "           Conv2d-79            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "             ReLU-81            [-1, 256, 8, 8]               0\n",
      "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "             ReLU-84            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-85            [-1, 256, 8, 8]               0\n",
      "           Conv2d-86            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 8, 8]             512\n",
      "             ReLU-88            [-1, 256, 8, 8]               0\n",
      "           Conv2d-89            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-90            [-1, 256, 8, 8]             512\n",
      "             ReLU-91            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-92            [-1, 256, 8, 8]               0\n",
      "           Conv2d-93            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-94            [-1, 256, 8, 8]             512\n",
      "             ReLU-95            [-1, 256, 8, 8]               0\n",
      "           Conv2d-96            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-97            [-1, 256, 8, 8]             512\n",
      "             ReLU-98            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-99            [-1, 256, 8, 8]               0\n",
      "          Conv2d-100            [-1, 512, 4, 4]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-102            [-1, 512, 4, 4]               0\n",
      "          Conv2d-103            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-105            [-1, 512, 4, 4]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-107            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-108            [-1, 512, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-111            [-1, 512, 4, 4]               0\n",
      "          Conv2d-112            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-114            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-115            [-1, 512, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-118            [-1, 512, 4, 4]               0\n",
      "          Conv2d-119            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-121            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-122            [-1, 512, 4, 4]               0\n",
      " ConvTranspose2d-123            [-1, 128, 8, 8]         262,272\n",
      "          Conv2d-124            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-125            [-1, 256, 8, 8]             512\n",
      "       UnetBlock-126            [-1, 256, 8, 8]               0\n",
      " ConvTranspose2d-127          [-1, 128, 16, 16]         131,200\n",
      "          Conv2d-128          [-1, 128, 16, 16]          16,512\n",
      "     BatchNorm2d-129          [-1, 256, 16, 16]             512\n",
      "       UnetBlock-130          [-1, 256, 16, 16]               0\n",
      " ConvTranspose2d-131          [-1, 128, 32, 32]         131,200\n",
      "          Conv2d-132          [-1, 128, 32, 32]           8,320\n",
      "     BatchNorm2d-133          [-1, 256, 32, 32]             512\n",
      "       UnetBlock-134          [-1, 256, 32, 32]               0\n",
      " ConvTranspose2d-135          [-1, 128, 64, 64]         131,200\n",
      "          Conv2d-136          [-1, 128, 64, 64]           8,320\n",
      "     BatchNorm2d-137          [-1, 256, 64, 64]             512\n",
      "       UnetBlock-138          [-1, 256, 64, 64]               0\n",
      " ConvTranspose2d-139          [-1, 6, 128, 128]           6,150\n",
      "================================================================\n",
      "Total params: 22,014,790\n",
      "Trainable params: 22,014,790\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 64.06\n",
      "Params size (MB): 83.98\n",
      "Estimated Total Size (MB): 148.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "    \n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_layers = base_model\n",
    "        \n",
    "        self.sfs = [SaveFeatures(base_model[i]) for i in [2,4,5,6]]\n",
    "        #                   up_in, x_in, n_out, up_out=x_out, size           \n",
    "        self.up1 = UnetBlock(512,   256,  256) #    128        7\n",
    "        self.up2 = UnetBlock(256,   128,  256) #    128       28\n",
    "        self.up3 = UnetBlock(256,   64,   256) #    128       56\n",
    "        self.up4 = UnetBlock(256,   64,   256) #    128      112\n",
    "        self.up5 = nn.ConvTranspose2d(256, 6, 2, stride=2)#  224\n",
    "#         self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.base_layers(x))\n",
    "#         import pdb; pdb.set_trace()\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "#         import pdb; pdb.set_trace()\n",
    "#         return x[:,0]\n",
    "        return x\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "\n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]\n",
    "    \n",
    "\n",
    "\n",
    "def get_base(base_model):\n",
    "#     base_model = models.resnet18(pretrained=True)\n",
    "    # keep all the layers upto the AdaptiveAvgPool2d layer\n",
    "    cut = next(i for i,o in enumerate(base_model.children()) if isinstance(o,nn.AdaptiveAvgPool2d))\n",
    "    return nn.Sequential(*list(base_model.children())[:cut])\n",
    "\n",
    "# f = resnet34\n",
    "# cut,lr_cut = model_meta[f]\n",
    "# def get_base():\n",
    "#     layers = cut_model(f(True), cut)\n",
    "#     return nn.Sequential(*layers) \n",
    "\n",
    "m_base = get_base(models.resnet34(pretrained=True))\n",
    "m = Unet(m_base).cuda()\n",
    "\n",
    "def run():\n",
    "    # model = UnetModel(m)\n",
    "#     import pdb; pdb.set_trace()\n",
    "    summary(m, (3, size, size))\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++\n",
      "ReLU(inplace=True)\n",
      "+++++++++++++++++++\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "+++++++++++++++++++\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "+++++++++++++++++++\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "base_model = m_base = get_base(models.resnet18(pretrained=True))\n",
    "\n",
    "for i in [2,4,5,6]:\n",
    "    print(\"+++++++++++++++++++\")\n",
    "    print(base_model[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "# print(device)\n",
    "if False:\n",
    "    model = ResNetUNet(6)\n",
    "else:\n",
    "    m_base = get_base(models.resnet18(pretrained=True))\n",
    "    model = Unet(m_base)\n",
    "\n",
    "# freeze backbone layers\n",
    "# Comment out to finetune further\n",
    "for l in model.base_layers:\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "## uses torch.nn.CrossEntropyLoss(...)    as a super class  \n",
    "# class myLoss2(nn.BCEWithLogitsLoss):    \n",
    "class myLoss2(nn.CrossEntropyLoss):    \n",
    "    def __init__(self, weight=None):\n",
    "        super(myLoss2, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        target = target.squeeze()\n",
    "        ret = super(myLoss2, self).forward(input, target)\n",
    "        return ret\n",
    "loss_func = myLoss2() \n",
    "\n",
    "def acc_camvid(input, target):\n",
    "#     target = target.float()\n",
    "        input = (input >0.5).long()\n",
    "        return (input==target).float().mean()\n",
    "lr=1e-4\n",
    "learn = Learner(data, model, loss_func = loss_func, metrics = metrics)\n",
    "# learn.fit_one_cycle(2, slice(lr), pct_start=0.9)\n",
    "# learn.freeze_to(1)\n",
    "# summary(model, (3, 224, 224))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 19 and 20 in dimension 2 at /pytorch/aten/src/THC/generic/THCTensorMath.cu:71",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8409aa144419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e5e1979c8978>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#         import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e5e1979c8978>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, up_p, x_p)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mup_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mcat_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mup_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 19 and 20 in dimension 2 at /pytorch/aten/src/THC/generic/THCTensorMath.cu:71"
     ]
    }
   ],
   "source": [
    "# %debug\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2227921c8cc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "lr=1e-4\n",
    "learn = Learner(data, model, loss_func = loss_func, metrics = metrics)\n",
    "learn.fit_one_cycle(10, slice(lr), pct_start=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_dl\n",
    "\n",
    "inputs, labels = next(iter(data.train_dl))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = learn.model(inputs)\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(data.train_dl))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = torch.sigmoid(model(inputs)).data.cpu().numpy()\n",
    "pred = model(inputs).data.cpu().numpy()\n",
    "\n",
    "pred.max(), pred.min(), pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_img(pred[0,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape, inputs.min(), inputs.max(), inputs.mean(), inputs.std()\n",
    "# Image(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img = open_image('data/FEC-half/positive/220972 - 1.jpg').resize(1380)\n",
    "\n",
    "# img = open_image('data/test/143268 - 2.jpg')\n",
    "img = PIL.Image.open(f'{path_img}/img3-9.png')\n",
    "\n",
    "show_img(img)\n",
    "print(np.asarray(img).max())\n",
    "# img = PIL.Image.open('data/220972 - 1.jpg')\n",
    "img = img.resize((128,128), resample=PIL.Image.BILINEAR)\n",
    "img = Image(pil2tensor(img,np.float32).div_(255))\n",
    "# img = Image(pil2tensor(img,np.float32))\n",
    "# img = Image(pil2tensor(img,np.float32))\n",
    "print(img.px.max())\n",
    "pc,pi,o = learn.predict(img)  \n",
    "\n",
    "pc.shape, pi.shape, o.shape, pc.px.max(), pi.max(), o.max()\n",
    "# pred_class[i] = pc.px\n",
    "\n",
    "# hstack = [torch.cat(pred_class[y:y+TN],dim=2) for y in range(0,TN*TM,TN)]  \n",
    "# vstack = torch.cat(hstack,dim=1)\n",
    "# Image(vstack).show(figsize = (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.px.max(), pi.max(), o.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1845
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2381,
     "status": "ok",
     "timestamp": 1554262413396,
     "user": {
      "displayName": "John Newton",
      "photoUrl": "https://lh3.googleusercontent.com/-CaBsDb97lHU/AAAAAAAAAAI/AAAAAAAAB34/lWIwjHZsHPY/s64/photo.jpg",
      "userId": "07245927208614369629"
     },
     "user_tz": -780
    },
    "id": "JvvlyHDvLqIX",
    "outputId": "8accbeed-374b-45fb-eefb-08de53b66286",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.show_results(rows=3, figsize=(10,20))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ZBxjRH1ojyv8"
   ],
   "name": "fastai_resnet34_unet.ipynb",
   "provenance": [
    {
     "file_id": "1tZ7vpvUJlrkk3nBn7SRG4kjnKh-sbEvN",
     "timestamp": 1554076846072
    },
    {
     "file_id": "https://github.com/usuyama/pytorch-unet/blob/master/pytorch_resnet18_unet.ipynb",
     "timestamp": 1554015433846
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}